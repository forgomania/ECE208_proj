{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df_seq=pd.read_csv('pdb_data_seq.csv')\n",
    "df_properties=pd.read_csv('pdb_data_no_dups.csv')\n",
    "df_total=df_seq.merge(df_properties,left_on='structureId',right_on = 'structureId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['structureId', 'chainId', 'sequence', 'residueCount_x',\n",
       "       'macromoleculeType_x', 'classification', 'experimentalTechnique',\n",
       "       'macromoleculeType_y', 'residueCount_y', 'resolution',\n",
       "       'structureMolecularWeight', 'crystallizationMethod',\n",
       "       'crystallizationTempK', 'densityMatthews', 'densityPercentSol',\n",
       "       'pdbxDetails', 'phValue', 'publicationYear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only protein, and filtered by top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the data in top n by count, top 10?\n",
    "count = df_total['classification'].value_counts(dropna=False)[:10]\n",
    "df_selected=df_total[df_total['classification'].isin(set(count.index))]\n",
    "#we want only protein\n",
    "df_selected=df_selected[df_selected['macromoleculeType_x'].isin(set(['Protein']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select proteins with only one chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select proteins with only one chain in the data set\n",
    "#how to justify this operation?\n",
    "#df_onechain = df_selected[df_selected.groupby('structureId').structureId.transform(len) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_selected[['structureId','classification','sequence']]\n",
    "#test_df = df_onechain[['structureId','classification','sequence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further select data and simplify problem, select proteins with only one chain?\n",
    "\n",
    "\n",
    "Figure out how to convert sequence data into array and training model afterwards.\n",
    "\n",
    "\n",
    "More models and discussion (*LSTM)\n",
    "\n",
    "Models build on features other than sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Focus on ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional, take part of the data for faster verification\n",
    "data = test_df.sample(100000)\n",
    "\n",
    "#need to remove nulls\n",
    "data = data.dropna()\n",
    "X_train, X_test,y_train,y_test = \\\n",
    "train_test_split(data['sequence'], data['classification'], test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction From Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lwx8999/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/lwx8999/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_type = [KNeighborsClassifier(),MultinomialNB(),RandomForestClassifier(), AdaBoostClassifier(),GradientBoostingClassifier(),DecisionTreeClassifier(),ExtraTreesClassifier()]\n",
    "model_score = {}\n",
    "def model_select(classifier):\n",
    "    model = classifier\n",
    "    model.fit(X_train_df, y_train)\n",
    "    #test on test set\n",
    "    NB_pred = model.predict(X_test_df)\n",
    "    return accuracy_score(NB_pred, y_test)\n",
    "for i in range(10):\n",
    "    #vectorize data, prepare for building models\n",
    "    #Convert a collection of text documents to a matrix of token counts\n",
    "    #seems has nothing to do with sequence but only with the frequency\n",
    "\n",
    "    #ngram is a parameter we need to focus on, \n",
    "    vect = CountVectorizer(analyzer = 'char_wb', ngram_range = (i,i))\n",
    "    vect.fit(X_train)\n",
    "    # Fit and Transform CountVectorizer\n",
    "    # Occasionally may meet np.nan error\n",
    "    X_train_df = vect.transform(X_train)\n",
    "    X_test_df = vect.transform(X_test)\n",
    "    model_score[i] = [model_select(j) for j in model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_select(classifier):\n",
    "    cv_result = []\n",
    "    cv_means = []\n",
    "    # Cross validate model with Kfold stratified cross val\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    cv_result.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n",
    "    cv_means.append(np.mean(cv_result))\n",
    "    return cv_means\n",
    "# Fitting all the models \n",
    "model_type = [KNeighborsClassifier(),GaussianNB(),RandomForestClassifier(),\n",
    "              AdaBoostClassifier(),GradientBoostingClassifier(),DecisionTreeClassifier(),ExtraTreesClassifier()]\n",
    "model_score = [model_select(i) for i in model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ['KNeighbors','Naive Bayes','Random Forest','AdaBoost','Gradient Boosting','Decision Tree','Extra Trees']\n",
    "# Place result in a data Frame\n",
    "ml_model = pd.DataFrame(model_score,classifier).reset_index()\n",
    "ml_model.columns=['Model','acc_score']\n",
    "ml_model.sort_values('acc_score',ascending = False,inplace=True)\n",
    "ml_model.reset_index(drop=True,inplace = True)\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.barplot('acc_score','Model',data=ml_model, ax=ax,palette='RdBu_r',edgecolor=\".2\")\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()+.01, i.get_y()+.55, \\\n",
    "        str(round((i.get_width()), 2)), fontsize=12, color='black') \n",
    "kwargs= {'length':3, 'width':1, 'colors':'black','labelsize':'large'}\n",
    "ax.tick_params(**kwargs)\n",
    "x_axis = ax.axes.get_xaxis().set_visible(False)\n",
    "ax.set_title('Model & Accuracy Score',fontsize=16)\n",
    "sns.despine(bottom=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
